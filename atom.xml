<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>马思夫的博客</title>
  
  <subtitle>我从未长大，但从未停止生长</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://maself.top/"/>
  <updated>2018-05-17T13:36:43.200Z</updated>
  <id>http://maself.top/</id>
  
  <author>
    <name>mamq</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>问卷调查——不同事件对社会稳定度的影响</title>
    <link href="http://maself.top/questionaire/"/>
    <id>http://maself.top/questionaire/</id>
    <published>2018-05-17T03:22:25.000Z</published>
    <updated>2018-05-17T13:36:43.200Z</updated>
    
    <content type="html"><![CDATA[<p><link rel="stylesheet" href="/css/input.css"></p><script type="text/javascript" src="/js/src/clipboard.js"></script><p><strong>由于本问卷中部分词汇涉及敏感词，无法使用常用的问卷工具，因此采用如此的曲线救国的方法，谢谢各位朋友的支持。</strong><br>本问卷仅作科研用途，不涉及任何隐私信息，希望您能够认真作答。<br>本问卷共设计26个问题，代表从新闻中挖掘出的26类事件。我们需要您根据您的经验判断<strong>每类事件反映社会稳定程度的能力大小</strong>，并为其赋予<em>-10~10</em>之间的值，负值代表不稳定，正值代表稳定。分值可以为小数。</p><blockquote><p>例如：我认为若一个国家的新闻中出现军事冲突事件，则某种程度上说明该国家社会稳定度较低，因此军事冲突事件反应社会稳定的能力为8,因其是负面影响，所以打分为-8。<br>若认为某一事件无法反应社会稳定程度，可将分值打为0左右。</p></blockquote><a id="more"></a><p>如有任何不同意见欢迎在最后的留言区留下建议，非常感谢。</p><p><strong>说明</strong>：</p><ol><li>“治安”事件为涉及到警察、犯罪的事件；</li><li>“核”事件为涉及到核能但与武器无关的事件；</li><li>“核武器”事件为涉及到核武器的事件；</li><li><strong>填写完毕后点击<em>复制答案到剪贴板</em>，然后<em>ctrl + v</em>将答案复制到评论框中，无需填写昵称和邮箱，直接提交即可。</strong></li></ol><h4 id="非常感谢"><a href="#非常感谢" class="headerlink" title="非常感谢!!!"></a>非常感谢!!!</h4><ol><li>“经济活动”事件:<input id="1" placeholder="-10~10"></li><li>“能源”事件:<input id="2" placeholder="-10~10"></li><li>“旅游”事件:<input id="3" placeholder="-10~10"></li><li>“娱乐”事件:<input id="4" placeholder="-10~10"></li><li>“航空”事件:<input id="5" placeholder="-10~10"></li><li>“航天”事件:<input id="6" placeholder="-10~10"></li><li>“法律”事件:<input id="7" placeholder="-10~10"></li><li>“教育”事件:<input id="8" placeholder="-10~10"></li><li>“港口”事件:<input id="9" placeholder="-10~10"></li><li>“政治”事件:<input id="10" placeholder="-10~10"></li><li>“健康”事件:<input id="11" placeholder="-10~10"></li><li>“宗教活动”事件:<input id="12" placeholder="-10~10"></li><li>“核”事件:<input id="13" placeholder="-10~10"></li><li>“拳击运动”事件:<input id="14" placeholder="-10~10"></li><li>“医疗”事件:<input id="15" placeholder="-10~10"></li><li>“宗教冲突”事件:<input id="16" placeholder="-10~10"></li><li>“种族冲突”事件:<input id="17" placeholder="-10~10"></li><li>“军事活动”事件:<input id="18" placeholder="-10~10"></li><li>“军事冲突”事件:<input id="19" placeholder="-10~10"></li><li>“袭击”事件:<input id="20" placeholder="-10~10"></li><li>“恐怖袭击”事件:<input id="21" placeholder="-10~10"></li><li>“恐怖主义”事件:<input id="22" placeholder="-10~10"></li><li>“核武器”事件:<input id="23" placeholder="-10~10"></li><li>“核制裁”事件:<input id="24" placeholder="-10~10"></li><li>“难民”事件:<input id="25" placeholder="-10~10"></li><li>“海盗”事件:<input id="26" placeholder="-10~10"></li><li>“毒品”事件:<input id="27" placeholder="-10~10"></li><li>“治安”事件:<input id="28" placeholder="-10~10"></li></ol><button type="button" onclick="copy()" class="btn btn-primary">复制答案到剪贴板</button>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;/css/input.css&quot;&gt;&lt;/p&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/clipboard.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;由于本问卷中部分词汇涉及敏感词，无法使用常用的问卷工具，因此采用如此的曲线救国的方法，谢谢各位朋友的支持。&lt;/strong&gt;&lt;br&gt;本问卷仅作科研用途，不涉及任何隐私信息，希望您能够认真作答。&lt;br&gt;本问卷共设计26个问题，代表从新闻中挖掘出的26类事件。我们需要您根据您的经验判断&lt;strong&gt;每类事件反映社会稳定程度的能力大小&lt;/strong&gt;，并为其赋予&lt;em&gt;-10~10&lt;/em&gt;之间的值，负值代表不稳定，正值代表稳定。分值可以为小数。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;例如：我认为若一个国家的新闻中出现军事冲突事件，则某种程度上说明该国家社会稳定度较低，因此军事冲突事件反应社会稳定的能力为8,因其是负面影响，所以打分为-8。&lt;br&gt;若认为某一事件无法反应社会稳定程度，可将分值打为0左右。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="python" scheme="http://maself.top/categories/python/"/>
    
    
      <category term="问卷调查" scheme="http://maself.top/tags/%E9%97%AE%E5%8D%B7%E8%B0%83%E6%9F%A5/"/>
    
  </entry>
  
  <entry>
    <title>matplotlib设置中英文多种字体混合坐标轴名称</title>
    <link href="http://maself.top/matplotlib-multifonts-xlabel/"/>
    <id>http://maself.top/matplotlib-multifonts-xlabel/</id>
    <published>2018-05-07T13:03:34.000Z</published>
    <updated>2018-05-07T14:05:29.892Z</updated>
    
    <content type="html"><![CDATA[<p>在利用matplotlib绘图时，常常需要添加图例与坐标轴名称，而在论文中，对中英文有严格的不同的字体要求，但默认的方法中(如下所示)，无法分别为中文、英文指定不同字体(如下图)，因此需要借助其他方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line"><span class="comment"># 在python中，字体单位貌似是px，与pt间的换算关系为1pt=4/3px</span></span><br><span class="line">simsun = FontProperities(fname=<span class="string">r'C:\Windows\Fonts\simsun.ttc'</span>, size=<span class="number">10</span>) </span><br><span class="line">plt.xlabel(<span class="string">u'Di距离'</span>, fontproperties=simsun)</span><br></pre></td></tr></table></figure></p><p><img src="http://p81hctxgb.bkt.clouddn.com/m2.PNG" alt="图1"></p><a id="more"></a><p>经过摸索后发现<em>text</em>函数能够在指定位置按照指定字体与大小显示文字，因此可以通过调整文字位置来实现xlabel的功能并且能够按照指定字体分别显示中英文(如下图)。代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> mpl, text</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line"><span class="comment"># windows下matplotlib显示中文一般有问题，需要专门进行设置才能正常显示</span></span><br><span class="line"><span class="comment"># 下面是两种设置的方式，使用时的参数也略有区别，在此不具体介绍</span></span><br><span class="line"><span class="comment"># 但需提前设置好，使得能够显示中文，否则中文字符位置显示为方框</span></span><br><span class="line">simsun = FontProperties(fname=<span class="string">r'C:\Windows\Fonts\simsun.ttc'</span>, size=<span class="number">10</span>) <span class="comment"># 宋体</span></span><br><span class="line">roman = FontProperties(fname=<span class="string">r'C:\Windows\Fonts\times.ttf'</span>, size=<span class="number">10</span>) <span class="comment"># Times new roman</span></span><br><span class="line">mpl.rcParams[<span class="string">'font.sans-serif'</span>] = [<span class="string">'SimSun'</span>]</span><br><span class="line">fontcn = &#123;<span class="string">'family'</span>: <span class="string">'SimSun'</span>,<span class="string">'size'</span>: <span class="number">10</span>&#125; <span class="comment"># 1pt = 4/3px</span></span><br><span class="line">fonten = &#123;<span class="string">'family'</span>:<span class="string">'Times New Roman'</span>,<span class="string">'size'</span>: <span class="number">10</span>&#125;</span><br><span class="line"></span><br><span class="line">plt.figure(<span class="number">1</span>)</span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)  <span class="comment"># 左图</span></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)  <span class="comment"># 右图</span></span><br><span class="line">plt.sca(ax1)</span><br><span class="line"></span><br><span class="line">plt.xlim(<span class="number">0</span>,<span class="number">150</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">0.08</span>)</span><br><span class="line">plt.xticks(range(<span class="number">0</span>,<span class="number">160</span>,<span class="number">10</span>),rotation=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#　设置斜体-Times New Roman字体</span></span><br><span class="line">text(<span class="number">60</span>, <span class="number">-0.01</span>, <span class="string">u'Di'</span>, style=<span class="string">'italic'</span>, fontdict=fonten) </span><br><span class="line">text(<span class="number">70</span>, <span class="number">-0.01</span>, <span class="string">u'距离'</span>, fontdict=fontcn)</span><br><span class="line">text(<span class="number">85</span>, <span class="number">-0.01</span>, <span class="string">u'(km)'</span>, fontdict=fonten)</span><br><span class="line">plt.ylabel(<span class="string">u"核密度"</span>, fontproperties=simsun)</span><br><span class="line">plt.title(<span class="string">u"a.核密度"</span>)</span><br><span class="line"></span><br><span class="line">plt.sca(ax2)</span><br><span class="line">plt.xlim(<span class="number">0</span>,<span class="number">150</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">plt.xticks(range(<span class="number">0</span>,<span class="number">160</span>,<span class="number">10</span>),rotation=<span class="number">0</span>)</span><br><span class="line">plt.yticks(np.linspace(<span class="number">0</span>,<span class="number">1</span>,<span class="number">11</span>))</span><br><span class="line"></span><br><span class="line">text(<span class="number">60</span>, <span class="number">-0.13</span>, <span class="string">u'Di'</span>, style=<span class="string">'italic'</span>, fontdict=fonten)</span><br><span class="line">text(<span class="number">70</span>, <span class="number">-0.13</span>, <span class="string">u'距离'</span>, fontdict=fontcn)</span><br><span class="line">text(<span class="number">85</span>, <span class="number">-0.13</span>, <span class="string">u'(km)'</span>, fontdict=fonten)</span><br><span class="line">plt.ylabel(<span class="string">u"累积概率"</span>, fontproperties=simsun)</span><br><span class="line">plt.title(<span class="string">u"b.累积概率"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></p><p><img src="http://p81hctxgb.bkt.clouddn.com/m3.PNG" alt="图2"></p><p>上述代码可直接运行，字体设置无误即可得到上图中的结果，但<code>Di距离(km)</code>可能会重叠或者空隙较大，这是正常情况，需要调整文字位置。<code>text</code>函数的前两个参数为其位置参数，都与其x轴、y轴坐标刻度有关，以&lt;<code>text(70, -0.01, u’距离’, fontdict=fontcn)</code>为例，70说明其水平方向位置在坐标轴70处，-0.01说明其垂直方向位置在-0.01刻度处，按照这个规则即可以多种字体显示多段文字。</p><hr><p>以上，欢迎留言交流～</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在利用matplotlib绘图时，常常需要添加图例与坐标轴名称，而在论文中，对中英文有严格的不同的字体要求，但默认的方法中(如下所示)，无法分别为中文、英文指定不同字体(如下图)，因此需要借助其他方法。&lt;br&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# -*- coding: utf-8 -*-&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; plt&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; matplotlib.font_manager &lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; FontProperties&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;# 在python中，字体单位貌似是px，与pt间的换算关系为1pt=4/3px&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;simsun = FontProperities(fname=&lt;span class=&quot;string&quot;&gt;r&#39;C:\Windows\Fonts\simsun.ttc&#39;&lt;/span&gt;, size=&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;) &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;plt.xlabel(&lt;span class=&quot;string&quot;&gt;u&#39;Di距离&#39;&lt;/span&gt;, fontproperties=simsun)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://p81hctxgb.bkt.clouddn.com/m2.PNG&quot; alt=&quot;图1&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="制图" scheme="http://maself.top/categories/%E5%88%B6%E5%9B%BE/"/>
    
    
      <category term="python" scheme="http://maself.top/tags/python/"/>
    
      <category term="matplotlib" scheme="http://maself.top/tags/matplotlib/"/>
    
      <category term="绘图" scheme="http://maself.top/tags/%E7%BB%98%E5%9B%BE/"/>
    
      <category term="多字体" scheme="http://maself.top/tags/%E5%A4%9A%E5%AD%97%E4%BD%93/"/>
    
  </entry>
  
  <entry>
    <title>python下进行lda主题挖掘(三)——计算困惑度perplexity</title>
    <link href="http://maself.top/py-lda-perplexity/"/>
    <id>http://maself.top/py-lda-perplexity/</id>
    <published>2018-05-01T12:11:28.000Z</published>
    <updated>2018-05-03T02:17:29.040Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://maself.top/py-lda-preprocess/">python下进行lda主题挖掘(一)——预处理(英文)</a><br><a href="http://maself.top/py-lda-train/">python下进行lda主题挖掘(二)——利用gensim训练LDA模型</a><br><a href="http://maself.top/py-lda-perplexity/">python下进行lda主题挖掘(三)——计算困惑度perplexity</a></p><hr><p>本篇是我的LDA主题挖掘系列的第三篇，专门来介绍如何对训练好的LDA模型进行评价。</p><blockquote><p>训练好好LDA主题模型后，如何评价模型的好坏？能否直接将训练好的模型拿去应用？这是一个比较重要的问题，在对模型精度要求比较高的项目或科研中，需要对模型进行评价。一般来说，LDA模型的主题数量都是需要需要根据具体任务进行调整的，即要评价不同主题数的模型的困惑度来选择最优的那个模型。</p></blockquote><a id="more"></a><p>那么，困惑度是什么？<br><strong>1.LDA主题模型困惑度</strong></p><p>这部分参照：<a href="http://blog.csdn.net/mandy_joe/article/details/41514097" target="_blank" rel="noopener">LDA主题模型评估方法–Perplexity</a>，不过后面发现这篇文章<a href="http://blog.csdn.net/jiaqiang_ruan/article/details/77989459?locationNum=2&amp;fps=1" target="_blank" rel="noopener">Perplexity(困惑度)</a>感觉写的更好一点，两篇都是翻译的维基百科。<br>perplexity是一种信息理论的测量方法，b的perplexity值定义为基于b的熵的能量（b可以是一个概率分布，或者概率模型），通常用于概率模型的比较<br>wiki上列举了三种perplexity的计算：<br>1.1 概率分布的perplexity<br>公式： <img src="http://p81hctxgb.bkt.clouddn.com/t1.png" alt="perplexity公式1"><br>其中H(p)就是该概率分布的熵。当概率P的K平均分布的时候，带入上式可以得到P的perplexity值=K。<br>1.2 概率模型的perplexity<br>公式：<img src="http://p81hctxgb.bkt.clouddn.com/t2.png" alt="perplexity公式2"><br>公式中的Xi为测试局，可以是句子或者文本，N是测试集的大小（用来归一化），对于未知分布q，perplexity的值越小，说明模型越好。<br>指数部分也可以用交叉熵来计算，略过不表。<br>1.3单词的perplexity<br>perplexity经常用于语言模型的评估，物理意义是单词的编码大小。例如，如果在某个测试语句上，语言模型的perplexity值为2^190，说明该句子的编码需要190bits<br><strong>2.困惑度perplexity公式</strong><br>$$ perplexity =  e^ {\frac{ - ∑log(p(w))}{N}} $$<br>其中，<strong>p(w)</strong>是指的测试集中出现的每一个词的概率，具体到LDA的模型中就是$p(w)=∑z p(z|d)<em>p(w|z)$ (</em>z,d分别指训练过的主题和测试集的各篇文档*)。分母的N是测试集中出现的所有词，或者说是测试集的总长度，不排重。</p><p><strong>3.计算困惑度的代码</strong></p><blockquote><p>下述代码中加载的.dictionary(字典)、.mm(语料)、.model(模型)文件均为在<a href="http://maself.top/py-lda-train/">python下进行lda主题挖掘(二)——利用gensim训练LDA模型</a>中得到的结果，如果文件格式与我不同，说明调用的不是同一个包，代码无法直接使用，可参考代码逻辑，若是已按照该博客中的方法得到上述文件，可直接调用下述代码计算困惑度。<br>PS：将语料经过TFIDF训练模型后计算得到的困惑度要远大于直接进行训练的困惑度（在我这边是这样），应该是正常情况，不必惊慌。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*-coding:utf-8-*-</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora, models</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s : '</span>, level=logging.INFO)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">perplexity</span><span class="params">(ldamodel, testset, dictionary, size_dictionary, num_topics)</span>:</span></span><br><span class="line">    <span class="string">"""calculate the perplexity of a lda-model"""</span></span><br><span class="line">    <span class="comment"># dictionary : &#123;7822:'deferment', 1841:'circuitry',19202:'fabianism'...]</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'the info of this ldamodel: \n'</span>)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">'num of testset: %s; size_dictionary: %s; num of topics: %s'</span>%(len(testset), size_dictionary, num_topics))</span><br><span class="line">    prep = <span class="number">0.0</span></span><br><span class="line">    prob_doc_sum = <span class="number">0.0</span></span><br><span class="line">    topic_word_list = [] <span class="comment"># store the probablity of topic-word:[(u'business', 0.010020942661849608),(u'family', 0.0088027946271537413)...]</span></span><br><span class="line">    <span class="keyword">for</span> topic_id <span class="keyword">in</span> range(num_topics):</span><br><span class="line">        topic_word = ldamodel.show_topic(topic_id, size_dictionary)</span><br><span class="line">        dic = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> word, probability <span class="keyword">in</span> topic_word:</span><br><span class="line">            dic[word] = probability</span><br><span class="line">        topic_word_list.append(dic)</span><br><span class="line">    doc_topics_ist = [] <span class="comment">#store the doc-topic tuples:[(0, 0.0006211180124223594),(1, 0.0006211180124223594),...]</span></span><br><span class="line">    <span class="keyword">for</span> doc <span class="keyword">in</span> testset:</span><br><span class="line">        doc_topics_ist.append(ldamodel.get_document_topics(doc, minimum_probability=<span class="number">0</span>))</span><br><span class="line">    testset_word_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(testset)):</span><br><span class="line">        prob_doc = <span class="number">0.0</span> <span class="comment"># the probablity of the doc</span></span><br><span class="line">        doc = testset[i]</span><br><span class="line">        doc_word_num = <span class="number">0</span> <span class="comment"># the num of words in the doc</span></span><br><span class="line">        <span class="keyword">for</span> word_id, num <span class="keyword">in</span> doc:</span><br><span class="line">            prob_word = <span class="number">0.0</span> <span class="comment"># the probablity of the word </span></span><br><span class="line">            doc_word_num += num</span><br><span class="line">            word = dictionary[word_id]</span><br><span class="line">            <span class="keyword">for</span> topic_id <span class="keyword">in</span> range(num_topics):</span><br><span class="line">                <span class="comment"># cal p(w) : p(w) = sumz(p(z)*p(w|z))</span></span><br><span class="line">                prob_topic = doc_topics_ist[i][topic_id][<span class="number">1</span>]</span><br><span class="line">                prob_topic_word = topic_word_list[topic_id][word]</span><br><span class="line">                prob_word += prob_topic*prob_topic_word</span><br><span class="line">            prob_doc += math.log(prob_word) <span class="comment"># p(d) = sum(log(p(w)))</span></span><br><span class="line">        prob_doc_sum += prob_doc</span><br><span class="line">        testset_word_num += doc_word_num</span><br><span class="line">    prep = math.exp(-prob_doc_sum/testset_word_num) <span class="comment"># perplexity = exp(-sum(p(d)/sum(Nd))</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"the perplexity of this ldamodel is : %s"</span>%prep)</span><br><span class="line">    <span class="keyword">return</span> prep</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    middatafolder = <span class="string">r'E:\work\lda'</span> + os.sep</span><br><span class="line">    dictionary_path = middatafolder + <span class="string">'dictionary.dictionary'</span></span><br><span class="line">    corpus_path = middatafolder + <span class="string">'corpus.mm'</span></span><br><span class="line">    ldamodel_path = middatafolder + <span class="string">'lda.model'</span></span><br><span class="line">    dictionary = corpora.Dictionary.load(dictionary_path)</span><br><span class="line">    corpus = corpora.MmCorpus(corpus_path)</span><br><span class="line">    lda_multi = models.ldamodel.LdaModel.load(ldamodel_path)</span><br><span class="line">    num_topics = <span class="number">50</span></span><br><span class="line">    testset = []</span><br><span class="line">    <span class="comment"># sample 1/300</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(corpus.num_docs/<span class="number">300</span>):</span><br><span class="line">        testset.append(corpus[i*<span class="number">300</span>])</span><br><span class="line">    prep = perplexity(lda_multi, testset, dictionary, len(dictionary.keys()), num_topics)</span><br></pre></td></tr></table></figure><p><strong>参考资料</strong></p><p>1.<a href="Perplexityblog.csdn.net/mandy_joe/article/details/41514097">LDA主题模型评估方法</a><br>2.<a href="http://blog.csdn.net/dongweionly/article/details/50286961" target="_blank" rel="noopener">LDA perplexity计算</a> java写的代码，本博客中的代码是参照改博客函数写的。<br>3.<a href="http://blog.csdn.net/jiaqiang_ruan/article/details/77989459?locationNum=2&amp;fps=1" target="_blank" rel="noopener">Perplexity(困惑度)</a></p><hr><p>以上，欢迎交流。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://maself.top/py-lda-preprocess/&quot;&gt;python下进行lda主题挖掘(一)——预处理(英文)&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://maself.top/py-lda-train/&quot;&gt;python下进行lda主题挖掘(二)——利用gensim训练LDA模型&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://maself.top/py-lda-perplexity/&quot;&gt;python下进行lda主题挖掘(三)——计算困惑度perplexity&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本篇是我的LDA主题挖掘系列的第三篇，专门来介绍如何对训练好的LDA模型进行评价。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;训练好好LDA主题模型后，如何评价模型的好坏？能否直接将训练好的模型拿去应用？这是一个比较重要的问题，在对模型精度要求比较高的项目或科研中，需要对模型进行评价。一般来说，LDA模型的主题数量都是需要需要根据具体任务进行调整的，即要评价不同主题数的模型的困惑度来选择最优的那个模型。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://maself.top/categories/NLP/"/>
    
    
      <category term="python" scheme="http://maself.top/tags/python/"/>
    
      <category term="lda" scheme="http://maself.top/tags/lda/"/>
    
      <category term="自然语言处理" scheme="http://maself.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="perplexity" scheme="http://maself.top/tags/perplexity/"/>
    
  </entry>
  
  <entry>
    <title>python下进行lda主题挖掘(二)——利用gensim训练LDA模型</title>
    <link href="http://maself.top/py-lda-train/"/>
    <id>http://maself.top/py-lda-train/</id>
    <published>2018-05-01T12:10:39.000Z</published>
    <updated>2018-05-03T02:17:35.352Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://maself.top/py-lda-preprocess/">python下进行lda主题挖掘(一)——预处理(英文)</a><br><a href="http://maself.top/py-lda-train/">python下进行lda主题挖掘(二)——利用gensim训练LDA模型</a><br><a href="http://maself.top/py-lda-perplexity/">python下进行lda主题挖掘(三)——计算困惑度perplexity</a></p><hr><p>本篇是我的LDA主题挖掘系列的第二篇，介绍如何利用gensim包提供的方法来训练自己处理好的语料。<br><a id="more"></a><br>gensim提供了多种方法：<br><strong>速度较慢的：</strong><br>具体参数说明及使用方法请参照官网：<a href="https://radimrehurek.com/gensim/models/ldamodel.html" target="_blank" rel="noopener">models.ldamodel – Latent Dirichlet Allocation</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models.ldamodel <span class="keyword">import</span> LdaModel</span><br><span class="line"><span class="comment"># 利用处理好的语料训练模型</span></span><br><span class="line">lda = LdaModel(corpus, num_topics=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 推断新文本的主题分布</span></span><br><span class="line">doc_lda = lda[doc_bow]</span><br><span class="line"><span class="comment"># 用新语料更新模型</span></span><br><span class="line">lda.update(other_corpus)</span><br></pre></td></tr></table></figure><p><strong>速度较快，使用多核心的：</strong><br>具体参数说明及使用方法请参照官网：<a href="https://radimrehurek.com/gensim/models/ldamulticore.html" target="_blank" rel="noopener">models.ldamulticore – parallelized Latent Dirichlet Allocation</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora, models </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lda = LdaMulticore(corpus, id2word=id2word, num_topics=<span class="number">100</span>)  <span class="comment"># train model</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(lda[doc_bow]) <span class="comment"># get topic probability distribution for a document</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>lda.update(corpus2) <span class="comment"># update the LDA model with additional documents</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(lda[doc_bow])</span><br></pre></td></tr></table></figure></p><p><strong>使用多进程对性能的提升：</strong></p><blockquote><p>Wall-clock performance on the English Wikipedia (2G corpus positions, 3.5M documents, 100K features, 0.54G non-zero entries in the final bag-of-words matrix), requesting 100 topics:<br>(Measured on this i7 server with 4 physical cores, so that optimal workers=3, one less than the number of cores.)</p></blockquote><table><thead><tr><th>algorithm</th><th style="text-align:center">training time</th></tr></thead><tbody><tr><td>LdaMulticore(workers=1)</td><td style="text-align:center">2h30m</td></tr><tr><td>LdaMulticore(workers=2)</td><td style="text-align:center">1h24m</td></tr><tr><td>LdaMulticore(workers=3)</td><td style="text-align:center">1h6m</td></tr><tr><td>oldLdaModel</td><td style="text-align:center">3h44m</td></tr><tr><td>simply iterating over input corpus = I/O overhead</td><td style="text-align:center">20m</td></tr></tbody></table><p><strong>workers的值需要比电脑的核心数小1</strong><br>本文代码使用多核心的方法。<br>有问题欢迎留言交流。<br>本文在将语料转化为corpus后，进行了如下操作：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tfidf = models.TfidfModel(corpus)</span><br><span class="line">corpusTfidf = tfidf[corpus]</span><br></pre></td></tr></table></figure></p><p>这一步是用来调整语料中不同词的词频，将那些在所有文档中都出现的高频词的词频降低，具体原理可参见阮一峰老师的系列博客：<a href="http://www.ruanyifeng.com/blog/2013/03/tf-idf.html" target="_blank" rel="noopener">TF-IDF与余弦相似性的应用（一）：自动提取关键词</a>，我经过这一步处理后，貌似效果提升不明显，而且这一步时间消耗较大，不建议采用。可直接将corpus作为训练数据传入lda模型中。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*-coding:utf-8-*-</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">from</span> gensim.corpora <span class="keyword">import</span> Dictionary</span><br><span class="line"><span class="keyword">from</span> gensim <span class="keyword">import</span> corpora, models</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(format=<span class="string">'%(asctime)s : %(levelname)s : %(message)s : '</span>, level=logging.INFO)</span><br><span class="line"></span><br><span class="line">platform_info = platform.platform().lower()</span><br><span class="line"><span class="keyword">if</span> <span class="string">'windows'</span> <span class="keyword">in</span> platform_info:</span><br><span class="line">    code = <span class="string">'gbk'</span></span><br><span class="line"><span class="keyword">elif</span> <span class="string">'linux'</span> <span class="keyword">in</span> platform_info:</span><br><span class="line">    code = <span class="string">'utf-8'</span></span><br><span class="line">path = sys.path[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GLDA</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""docstring for GdeltGLDA"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stopfile=None)</span>:</span></span><br><span class="line">        super(GLDA, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> stopfile:</span><br><span class="line">            <span class="keyword">with</span> codecs.open(stopfile, <span class="string">'r'</span>, code) <span class="keyword">as</span> f:</span><br><span class="line">                self.stopword_list = f.read().split(<span class="string">' '</span>)</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">'the num of stopwords is : %s'</span>%len(self.stopword_list))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.stopword_list = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lda_train</span><span class="params">(self, num_topics, datafolder, middatafolder, dictionary_path= \</span></span></span><br><span class="line"><span class="function"><span class="params">    None, corpus_path=None, iterations=<span class="number">5000</span>, passes=<span class="number">1</span>, workers=<span class="number">3</span>)</span>:</span>       </span><br><span class="line">        time1 = datetime.now()</span><br><span class="line">        num_docs = <span class="number">0</span></span><br><span class="line">        doclist = []</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> corpus_path <span class="keyword">or</span> <span class="keyword">not</span> dictionary_path: <span class="comment"># 若无字典或无corpus，则读取预处理后的docword。一般第一次运行都需要读取，在后期调参时，可直接传入字典与corpus路径</span></span><br><span class="line">            <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(datafolder): <span class="comment"># 读取datafolder下的语料</span></span><br><span class="line">                <span class="keyword">with</span> codecs.open(datafolder+filename, <span class="string">'r'</span>, code) <span class="keyword">as</span> source_file:</span><br><span class="line">                    <span class="keyword">for</span> line <span class="keyword">in</span> source_file:</span><br><span class="line">                        num_docs += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">if</span> num_docs%<span class="number">100000</span>==<span class="number">0</span>:</span><br><span class="line">                            <span class="keyword">print</span> (<span class="string">'%s, %s'</span>%(filename, num_docs))</span><br><span class="line">                        <span class="comment">#doc = [word for word in doc if word not in self.stopword_list]</span></span><br><span class="line">                        doclist.append(line.split(<span class="string">' '</span>))</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">'%s, %s'</span>%(filename, num_docs))</span><br><span class="line">        <span class="keyword">if</span> dictionary_path:</span><br><span class="line">            dictionary = corpora.Dictionary.load(dictionary_path) <span class="comment"># 加载字典</span></span><br><span class="line">        <span class="keyword">else</span>:            </span><br><span class="line">            <span class="comment">#构建词汇统计向量并保存</span></span><br><span class="line">            dictionary = corpora.Dictionary(doclist)</span><br><span class="line">            dictionary.save(middatafolder + <span class="string">'dictionary.dictionary'</span>)</span><br><span class="line">        <span class="keyword">if</span> corpus_path:</span><br><span class="line">            corpus = corpora.MmCorpus(corpus_path) <span class="comment"># 加载corpus</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            corpus = [dictionary.doc2bow(doc) <span class="keyword">for</span> doc <span class="keyword">in</span> doclist]</span><br><span class="line">            corpora.MmCorpus.serialize(middatafolder + <span class="string">'corpus.mm'</span>, corpus) <span class="comment"># 保存corpus</span></span><br><span class="line">        tfidf = models.TfidfModel(corpus)</span><br><span class="line">        corpusTfidf = tfidf[corpus]</span><br><span class="line">        time2 = datetime.now()</span><br><span class="line">        lda_multi = models.ldamulticore.LdaMulticore(corpus=corpusTfidf, id2word=dictionary, num_topics=num_topics, \</span><br><span class="line">            iterations=iterations, workers=workers, batch=<span class="keyword">True</span>, passes=passes) <span class="comment"># 开始训练</span></span><br><span class="line">        lda_multi.print_topics(num_topics, <span class="number">30</span>) <span class="comment"># 输出主题词矩阵</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'lda training time cost is : %s, all time cost is : %s '</span>%(datetime.now()-time2, datetime.now()-time1))</span><br><span class="line">        <span class="comment">#模型的保存/ 加载</span></span><br><span class="line">        lda_multi.save(middatafolder + <span class="string">'lda_tfidf_%s_%s.model'</span>%(<span class="number">2014</span>, num_topics, iterations)) <span class="comment"># 保存模型</span></span><br><span class="line">        <span class="comment"># lda = models.ldamodel.LdaModel.load('zhwiki_lda.model') # 加载模型</span></span><br><span class="line">        <span class="comment"># save the doc-topic-id</span></span><br><span class="line">        topic_id_file = codecs.open(middatafolder + <span class="string">'topic.json'</span>, <span class="string">'w'</span>, <span class="string">'utf-8'</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(num_docs):</span><br><span class="line">            topic_id = lda_multi[corpusTfidf[i]][<span class="number">0</span>][<span class="number">0</span>] <span class="comment"># 取概率最大的主题作为文本所属主题</span></span><br><span class="line">            topic_id_file.write(str(topic_id)+ <span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    datafolder = path + os.sep + <span class="string">'docword'</span> + os.sep <span class="comment"># 预处理后的语料所在文件夹，函数会读取此文件夹下的所有语料文件</span></span><br><span class="line">    middatafolder = path + os.sep + <span class="string">'middata'</span> + os.sep</span><br><span class="line">    dictionary_path = middatafolder + <span class="string">'dictionary.dictionary'</span> <span class="comment"># 已处理好的字典，若无，则设置为False</span></span><br><span class="line">    corpus_path = middatafolder + <span class="string">'corpus.mm'</span> <span class="comment"># 对语料处理过后的corpus，若无，则设置为False</span></span><br><span class="line">    <span class="comment"># stopfile = path + os.sep + 'rest_stopwords.txt' # 新添加的停用词文件</span></span><br><span class="line">    num_topics = <span class="number">50</span></span><br><span class="line">    passes = <span class="number">2</span> <span class="comment"># 这个参数大概是将全部语料进行训练的次数，数值越大，参数更新越多，耗时更长</span></span><br><span class="line">    iterations = <span class="number">6000</span></span><br><span class="line">    workers = <span class="number">3</span> <span class="comment"># 相当于进程数</span></span><br><span class="line">    lda = GLDA()</span><br><span class="line">    lda.lda_train(num_topics, datafolder, middatafolder, dictionary_path=dictionary_path, corpus_path=corpus_path, iterations=iterations, passes=passes, workers=workers)</span><br></pre></td></tr></table></figure></p><p>在训练好模型后该如何对模型进行评价，以选取合适的参数？<br>可参照下一篇博客<a href="http://maself.top/py-lda-perplexity/">python下进行lda主题挖掘(三)——计算困惑度</a></p><hr><p>以上，欢迎交流与指正。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://maself.top/py-lda-preprocess/&quot;&gt;python下进行lda主题挖掘(一)——预处理(英文)&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://maself.top/py-lda-train/&quot;&gt;python下进行lda主题挖掘(二)——利用gensim训练LDA模型&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://maself.top/py-lda-perplexity/&quot;&gt;python下进行lda主题挖掘(三)——计算困惑度perplexity&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本篇是我的LDA主题挖掘系列的第二篇，介绍如何利用gensim包提供的方法来训练自己处理好的语料。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://maself.top/categories/NLP/"/>
    
    
      <category term="python" scheme="http://maself.top/tags/python/"/>
    
      <category term="lda" scheme="http://maself.top/tags/lda/"/>
    
      <category term="自然语言处理" scheme="http://maself.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="主题挖掘" scheme="http://maself.top/tags/%E4%B8%BB%E9%A2%98%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>python下进行lda主题挖掘(一)——预处理(英文)</title>
    <link href="http://maself.top/py-lda-preprocess/"/>
    <id>http://maself.top/py-lda-preprocess/</id>
    <published>2018-05-01T12:08:10.000Z</published>
    <updated>2018-05-03T02:17:25.060Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://maself.top/py-lda-preprocess/">python下进行lda主题挖掘(一)——预处理(英文)</a><br><a href="http://maself.top/py-lda-train/">python下进行lda主题挖掘(二)——利用gensim训练LDA模型</a><br><a href="http://maself.top/py-lda-perplexity/">python下进行lda主题挖掘(三)——计算困惑度perplexity</a></p><hr><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>本人打算将LDA这部分的内容写成一个系列，不涉及算法思想，只分享代码与使用经验，包括但不限于以下内容：英文文档的预处理、LDA主题提取、perplexity计算。<br>运行环境：python27，windows-Linux皆可<br>代码如有纰漏或不完善之处，欢迎批评指正。<br><a id="more"></a></p><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>英文文档的预处理主要包括以下几部分的内容：</p><ul><li>单词分割(英文比较简单，中文就得借助于结巴分词之类的包了)</li><li>去除停用词</li><li>去除标点、数字</li><li>词形还原</li><li>词干提取</li><li>去除非英文单词的内容</li></ul><p>停用词表可以在网上下载，主要包括一些对语义无帮助的单词以及字母等。不过根据任务的不同最好建立适用于语料库的停用词表，提高结果的可解释性。<br> 词形还原可以将单词的不同时态或单复数进行统一，能够减少词汇表的大小，建议必须要有这一步；<br> 词干提取则是直接提取单词的词根，如busy、business都会提取为busi，这一步能够大量的减少词汇量，但是也会导致歧义，因为不同词义的单词可能对应于同一个词根，所以这一步需要酌情考虑。<br> 下面贴代码。写了一个预处理类，提供三种功能：</p><ul><li>处理文件夹下的所有文件</li><li>处理单个文件</li><li>多进程处理文件夹下的所有文件</li></ul><p>主要部分都有注释</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*-coding:utf-8-*-</span></span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer </span><br><span class="line"><span class="keyword">from</span> nltk.stem.porter <span class="keyword">import</span> PorterStemmer</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> wordnet</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</span><br><span class="line">path = sys.path[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NlpPreProcess</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="string">"""preprocess the html of gdelt-data</span></span><br><span class="line"><span class="string">    arg: str</span></span><br><span class="line"><span class="string">        filepath of the stoplist-file</span></span><br><span class="line"><span class="string">    function: </span></span><br><span class="line"><span class="string">        preprocess_folder(source_folder, dest_folder): preprocess all files in the source-folder, and save the results to dest-folder</span></span><br><span class="line"><span class="string">        preprocess_file(doc): preprocess a doc, delete the punctuation,digit,meanningless word</span></span><br><span class="line"><span class="string">        generate_dict_from_file(filename): generator to parse dict from json file</span></span><br><span class="line"><span class="string">    &gt;&gt;&gt;nlp_preprocess = NlpPreProcess('')"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, stopfile, downlist)</span>:</span></span><br><span class="line">        super(NlpPreProcess, self).__init__()</span><br><span class="line">        self.wnl = WordNetLemmatizer() <span class="comment"># 词形还原</span></span><br><span class="line">        self.ps = PorterStemmer() <span class="comment"># 词干提取</span></span><br><span class="line">        <span class="keyword">with</span> codecs.open(stopfile, <span class="string">'r'</span>, <span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            self.stoplist = f.read().splitlines()</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'the num of stopwords is %s'</span>%len(self.stoplist))</span><br><span class="line">        self.downlist = downlist <span class="comment"># 文件夹下已经处理过的文档，避免重复抓取</span></span><br><span class="line">        self.allnum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess_folder</span><span class="params">(self, source_folder, dest_folder)</span>:</span></span><br><span class="line">        <span class="string">'''process all docs in all files, and save the results to according docwords file'''</span></span><br><span class="line">        stime = datetime.now()</span><br><span class="line">        <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(source_folder):</span><br><span class="line">            self.preprocess_file(filename, source_folder, dest_folder)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'the num of all valid docs is : %s'</span>%self.allnum)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess_folder_multiprocess</span><span class="params">(self, source_folder, dest_folder, process_num)</span>:</span></span><br><span class="line">        <span class="string">'''process all docs in all files, and save the results to according docwords file'''</span></span><br><span class="line">        filelist = os.listdir(source_folder)</span><br><span class="line">        tmp = []</span><br><span class="line">        process_list = []</span><br><span class="line">        num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(filelist)):</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">'docwords'</span>+filelist[i<span class="number">-1</span>] <span class="keyword">in</span> downlist: <span class="comment"># 如果已处理则跳过</span></span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            tmp.append(filelist[i<span class="number">-1</span>])</span><br><span class="line">            num += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> num%process_num == <span class="number">0</span> <span class="keyword">or</span> i==len(filelist):</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">"the %dth loop"</span>%(num/process_num))</span><br><span class="line">                <span class="keyword">print</span> (<span class="string">'------'</span>*<span class="number">20</span>)</span><br><span class="line">                <span class="keyword">for</span> filename <span class="keyword">in</span> tmp:</span><br><span class="line">                    process_list.append(multiprocessing.Process(target=self.preprocess_file, args=(filename, source_folder, dest_folder)))</span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">                    p.start()</span><br><span class="line">                <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">                    p.join()</span><br><span class="line">                tmp = []</span><br><span class="line">                process_list = []</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'the num of all valid docs is : %s'</span>%self.allnum)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preprocess_file</span><span class="params">(self, filename, source_folder, dest_folder)</span>:</span></span><br><span class="line">        <span class="string">'''去标点, 去数字, 分割成单词, 词形还原'''</span></span><br><span class="line">        saveFileName = <span class="string">'docwords'</span>+filename[<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> saveFileName <span class="keyword">in</span> self.downlist:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'begin process %s'</span>%filename)</span><br><span class="line">        save_file = codecs.open(dest_folder + os.sep + saveFileName, <span class="string">'w'</span>, <span class="string">'utf-8'</span>)</span><br><span class="line">        num = <span class="number">0</span></span><br><span class="line">        stime = datetime.now()</span><br><span class="line">        <span class="keyword">for</span> dic <span class="keyword">in</span> self.generate_dict_from_file(source_folder + os.sep + filename):</span><br><span class="line">            doc = dic[<span class="string">'content'</span>].lower()</span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> string.punctuation: <span class="comment">#去标点</span></span><br><span class="line">                doc = doc.replace(c, <span class="string">' '</span>)</span><br><span class="line">            <span class="keyword">for</span> c <span class="keyword">in</span> string.digits: <span class="comment">#去数字</span></span><br><span class="line">                doc = doc.replace(c, <span class="string">''</span>)</span><br><span class="line">            doc = nltk.word_tokenize(doc) <span class="comment">#分割成单词</span></span><br><span class="line">            <span class="comment"># 只保留特定词性单词, 如名词</span></span><br><span class="line">            <span class="comment"># filter = nltk.pos_tag(doc)</span></span><br><span class="line">            <span class="comment"># doc = [w for w, pos in filter if pos.startswith("NN")]</span></span><br><span class="line">            cleanDoc = []</span><br><span class="line">            <span class="comment"># 只保留长度不小于3的单词,去除停用词,验证是否为英文单词(利用wordnet)</span></span><br><span class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> doc:</span><br><span class="line">                <span class="keyword">if</span> len(word) &gt;= <span class="number">3</span> <span class="keyword">and</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.stoplist <span class="keyword">and</span> wordnet.synsets(word):</span><br><span class="line">                    word = self.wnl.lemmatize(word) <span class="comment">#词形还原</span></span><br><span class="line">                    <span class="comment">#word = self.ps.stem(word) # 词干提取</span></span><br><span class="line">                    cleanDoc.append(word)</span><br><span class="line">            dic[<span class="string">'content'</span>] = <span class="string">' '</span>.join(cleanDoc)</span><br><span class="line">            json.dump(dic, save_file, ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line">            save_file.write(<span class="string">'\n'</span>)</span><br><span class="line">            num += <span class="number">1</span></span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'time cost is : %s'</span>%(datetime.now()-stime))</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'the num of valid docs is : %s'</span>%num)</span><br><span class="line">        <span class="keyword">print</span> (<span class="string">'---'</span>*<span class="number">20</span>)</span><br><span class="line">        self.allnum += num</span><br><span class="line">        <span class="keyword">return</span> num</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generate_dict_from_file</span><span class="params">(self, filename)</span>:</span></span><br><span class="line">        <span class="string">"""读取json文件，返回字典数据"""</span></span><br><span class="line">        <span class="keyword">with</span> codecs.open(filename, <span class="string">'r'</span>, <span class="string">'utf-8'</span>) <span class="keyword">as</span> source_file:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> source_file:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    dic = json.loads(line.strip())</span><br><span class="line">                    <span class="keyword">yield</span> dic</span><br><span class="line">                <span class="keyword">except</span>:</span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    source_folder = path + os.sep + <span class="string">'cleanHtml'</span></span><br><span class="line">    dest_folder = path + os.sep + <span class="string">'docword'</span></span><br><span class="line">    stopword_filepath = path + os.sep + <span class="string">'stoplist.csv'</span></span><br><span class="line">    process_num = <span class="number">6</span> <span class="comment"># 设置多进程数量</span></span><br><span class="line">    downlist = os.listdir(dest_folder)</span><br><span class="line">    nlp_preprocess = NlpPreProcess(stopword_filepath, downlist)</span><br><span class="line">    nlp_preprocess.preprocess_file(<span class="string">'sogou.json'</span>, source_folder, dest_folder)</span><br><span class="line">    <span class="comment">#nlp_preprocess.preprocess_folder_multiprocess(source_folder, dest_folder, process_num)</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://maself.top/py-lda-preprocess/&quot;&gt;python下进行lda主题挖掘(一)——预处理(英文)&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://maself.top/py-lda-train/&quot;&gt;python下进行lda主题挖掘(二)——利用gensim训练LDA模型&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://maself.top/py-lda-perplexity/&quot;&gt;python下进行lda主题挖掘(三)——计算困惑度perplexity&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&quot;写在前面&quot;&gt;&lt;a href=&quot;#写在前面&quot; class=&quot;headerlink&quot; title=&quot;写在前面&quot;&gt;&lt;/a&gt;写在前面&lt;/h2&gt;&lt;p&gt;本人打算将LDA这部分的内容写成一个系列，不涉及算法思想，只分享代码与使用经验，包括但不限于以下内容：英文文档的预处理、LDA主题提取、perplexity计算。&lt;br&gt;运行环境：python27，windows-Linux皆可&lt;br&gt;代码如有纰漏或不完善之处，欢迎批评指正。&lt;br&gt;
    
    </summary>
    
      <category term="NLP" scheme="http://maself.top/categories/NLP/"/>
    
    
      <category term="python" scheme="http://maself.top/tags/python/"/>
    
      <category term="lda" scheme="http://maself.top/tags/lda/"/>
    
      <category term="自然语言处理" scheme="http://maself.top/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>利用python将json数据转换为csv格式</title>
    <link href="http://maself.top/py-json2csv/"/>
    <id>http://maself.top/py-json2csv/</id>
    <published>2018-05-01T12:05:54.000Z</published>
    <updated>2018-05-02T08:43:20.545Z</updated>
    
    <content type="html"><![CDATA[<p>假设.json文件中存储的数据为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">"type"</span>: <span class="string">"Point"</span>, <span class="string">"link"</span>: <span class="string">"http://www.dianping.com/newhotel/22416995"</span>, <span class="string">"coordinates"</span>: [<span class="number">116.37256372996957</span>, <span class="number">40.39798447055443</span>], <span class="string">"category"</span>: <span class="string">"经济型"</span>, <span class="string">"name"</span>: <span class="string">"北京荷塘山庄"</span>, <span class="string">"count"</span>: <span class="string">"278"</span>, <span class="string">"address"</span>: <span class="string">"北京市怀柔区黄花城村安四路"</span>, <span class="string">"price"</span>: <span class="string">"380"</span>&#125;</span><br><span class="line">&#123;<span class="string">"type"</span>: <span class="string">"Point"</span>, <span class="string">"link"</span>: <span class="string">"http://www.dianping.com/newhotel/19717653"</span>, <span class="string">"coordinates"</span>: [<span class="number">116.56881588256466</span>, <span class="number">40.43310967948417</span>], <span class="string">"category"</span>: <span class="string">"经济型"</span>, <span class="string">"name"</span>: <span class="string">"慕田峪长城鱼师傅乡村酒店"</span>, <span class="string">"count"</span>: <span class="string">"89"</span>, <span class="string">"address"</span>: <span class="string">"北京市怀柔区渤海镇苇店村(慕田峪长城下3公里处，近怀黄路)"</span>, <span class="string">"price"</span>: <span class="string">"258"</span>&#125;</span><br></pre></td></tr></table></figure><p>现在需要将上面的这些数据存为csv格式，其中字典的keys为csv中的属性名称，字典的values为csv中属性对应的值。<br><a id="more"></a></p><hr><p>如果只需要按照json的keys来生成csv，那么操作比较简单，直接按照下面的方法即可：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*-coding:utf-8-*-</span></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trans</span><span class="params">(path)</span>:</span></span><br><span class="line">    jsonData = codecs.open(path+<span class="string">'.json'</span>, <span class="string">'r'</span>, <span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment"># csvfile = open(path+'.csv', 'w') # 此处这样写会导致写出来的文件会有空行</span></span><br><span class="line">    <span class="comment"># csvfile = open(path+'.csv', 'wb') # python2下</span></span><br><span class="line">    csvfile = open(path+<span class="string">'.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) <span class="comment"># python3下</span></span><br><span class="line">    writer = csv.writer(csvfile, delimiter=<span class="string">'\t'</span>, quoting=csv.QUOTE_ALL)</span><br><span class="line">    flag = <span class="keyword">True</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> jsonData:</span><br><span class="line">        dic = json.loads(line[<span class="number">0</span>:<span class="number">-1</span>])</span><br><span class="line">        <span class="keyword">if</span> flag:</span><br><span class="line">            <span class="comment"># 获取属性列表</span></span><br><span class="line">            keys = list(dic.keys())</span><br><span class="line">            <span class="keyword">print</span> (keys)</span><br><span class="line">            writer.writerow(keys) <span class="comment"># 将属性列表写入csv中</span></span><br><span class="line">            flag = <span class="keyword">False</span></span><br><span class="line">        <span class="comment"># 读取json数据的每一行，将values数据一次一行的写入csv中</span></span><br><span class="line">        writer.writerow(list(dic.values()))</span><br><span class="line">    jsonData.close()</span><br><span class="line">    csvfile.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    path=str(sys.argv[<span class="number">1</span>]) <span class="comment"># 获取path参数</span></span><br><span class="line">    <span class="keyword">print</span> (path)</span><br><span class="line">    trans(path)</span><br></pre></td></tr></table></figure><p>在python3下运行，命令行输入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python C:\Users\MaMQ\Documents\jsonToCsv.py C:\Users\MaMQ\Documents\data\geoFood</span><br></pre></td></tr></table></figure><p>其中第三个参数为需要转换的文件的路径和其名称，将其后缀删除。运行文件后即可得到转换后的csv文件。</p><hr><p>如果需要对json文件中每个字典的key字段进行修改，比如需要将上面dict中的coordinate中的经纬度数据取出来存为x、y数据，则可以按照下面的方法（此方法还可以调整每个属性显示的顺序，效果更好一点）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trans</span><span class="params">(path)</span>:</span></span><br><span class="line">    jsonData = codecs.open(path+<span class="string">'.json'</span>, <span class="string">'r'</span>, <span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment"># csvfile = open(path+'.csv', 'w') # 此处这样写会导致写出来的文件会有空行</span></span><br><span class="line">    <span class="comment"># csvfile = open(path+'.csv', 'wb') # python2下</span></span><br><span class="line">    csvfile = open(path+<span class="string">'.csv'</span>, <span class="string">'w'</span>, newline=<span class="string">''</span>) <span class="comment"># python3下</span></span><br><span class="line">    writer = csv.writer(csvfile, delimiter=<span class="string">'\t'</span>, quoting=csv.QUOTE_ALL)</span><br><span class="line">    keys=[<span class="string">'id'</span>, <span class="string">'name'</span>, <span class="string">'category'</span>, <span class="string">'price'</span>, <span class="string">'count'</span>, <span class="string">'type'</span>, <span class="string">'address'</span>, <span class="string">'link'</span>, <span class="string">'x'</span>, <span class="string">'y'</span>]</span><br><span class="line">    writer.writerow(keys)</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> dic <span class="keyword">in</span> jsonData:</span><br><span class="line">        dic = json.loads(dic[<span class="number">0</span>:<span class="number">-1</span>])</span><br><span class="line">        x = dic[<span class="string">'coordinates'</span>][<span class="number">0</span>]</span><br><span class="line">        y = dic[<span class="string">'coordinates'</span>][<span class="number">1</span>]</span><br><span class="line">        writer.writerow([str(i),dic[<span class="string">'name'</span>],dic[<span class="string">'category'</span>],dic[<span class="string">'price'</span>],dic[<span class="string">'count'</span>],dic[<span class="string">'type'</span>],dic[<span class="string">'address'</span>],dic[<span class="string">'link'</span>],x,y])</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    jsonData.close()</span><br><span class="line">    csvfile.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    path = str(sys.argv[<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">print</span> (path)</span><br><span class="line">    trans(path)</span><br></pre></td></tr></table></figure><p>运行方法同上。<br>json文件是我在大众点评抓取的数据，存储格式为utf-8。建议使用codecs包来读取json数据，可指定编码方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jsonData = codecs.open(path + <span class="string">'.json'</span>, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>)</span><br></pre></td></tr></table></figure><p>欢迎交流讨论。</p><hr><p>参考资料：<br><a href="http://blog.csdn.net/huitailang1991/article/details/54946528" target="_blank" rel="noopener">csv.writer写入文件有多余的空行</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;假设.json文件中存储的数据为：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Point&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;link&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://www.dianping.com/newhotel/22416995&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;: [&lt;span class=&quot;number&quot;&gt;116.37256372996957&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;40.39798447055443&lt;/span&gt;], &lt;span class=&quot;string&quot;&gt;&quot;category&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;经济型&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;北京荷塘山庄&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;count&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;278&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;address&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;北京市怀柔区黄花城村安四路&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;price&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;380&quot;&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;span class=&quot;string&quot;&gt;&quot;type&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;Point&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;link&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;http://www.dianping.com/newhotel/19717653&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;coordinates&quot;&lt;/span&gt;: [&lt;span class=&quot;number&quot;&gt;116.56881588256466&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;40.43310967948417&lt;/span&gt;], &lt;span class=&quot;string&quot;&gt;&quot;category&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;经济型&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;name&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;慕田峪长城鱼师傅乡村酒店&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;count&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;89&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;address&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;北京市怀柔区渤海镇苇店村(慕田峪长城下3公里处，近怀黄路)&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;price&quot;&lt;/span&gt;: &lt;span class=&quot;string&quot;&gt;&quot;258&quot;&lt;/span&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;现在需要将上面的这些数据存为csv格式，其中字典的keys为csv中的属性名称，字典的values为csv中属性对应的值。&lt;br&gt;
    
    </summary>
    
      <category term="python" scheme="http://maself.top/categories/python/"/>
    
    
      <category term="python" scheme="http://maself.top/tags/python/"/>
    
      <category term="json" scheme="http://maself.top/tags/json/"/>
    
      <category term="csv" scheme="http://maself.top/tags/csv/"/>
    
  </entry>
  
  <entry>
    <title>python下利用opencv提取surf特征并保存</title>
    <link href="http://maself.top/py-opencv-surf/"/>
    <id>http://maself.top/py-opencv-surf/</id>
    <published>2018-04-30T08:06:00.000Z</published>
    <updated>2018-05-07T14:01:02.744Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、算法背景介绍"><a href="#一、算法背景介绍" class="headerlink" title="一、算法背景介绍"></a>一、算法背景介绍</h2><p>Lowe于2000年提出了SIFT算法，并于2004年加以完善和改进，SIFT特征对图像旋转、平移、缩放、亮度变化能够保持良好的不变性，且其独特性好，信息量较为丰富，得到了广泛的应用，但其提取计算量较大，效率较低，因此Bay等人提出了SURF算法，在保证特征点数量的情况下，提高了效率。<br>SURF算法首先构建Hessian矩阵，然后构建尺度空间(SIFT算法则使用DOG)，其在构建图像金字塔时原始图像大小保持不变，只改变滤波器大小，然后精确定位特征点并确定其主方向，最后生成特征点描述子。<br>此外，SURF算法得到的特征向量维度为64，而SIFT得到的是128维向量。<br><a id="more"></a></p><h2 id="二、实现代码"><a href="#二、实现代码" class="headerlink" title="二、实现代码"></a>二、实现代码</h2><p>下述代码计算images_folder文件夹下的所有图片的SURF特征，然后将图片与特征向量其保存到指定文件夹<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*-coding:utf-8-*-</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">path = sys.path[<span class="number">0</span>] + os.sep</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feature_extract</span><span class="params">(images_folder, draw_folder)</span>:</span></span><br><span class="line">    featureSum = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(images_folder):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">'.jpg'</span> <span class="keyword">in</span> filename:</span><br><span class="line">            filepath + images_folder + filename</span><br><span class="line">            drawpath = draw_folder + filename  </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">continue</span>  </span><br><span class="line">        img = cv2.imread(filepath)</span><br><span class="line">        filename = filepath.split(os.sep)[<span class="number">-1</span>].split(<span class="string">'.'</span>)[<span class="number">0</span>]</span><br><span class="line">        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)</span><br><span class="line">        <span class="comment"># set Hessian threshold</span></span><br><span class="line">        detector = cv2.xfeatures2d.SURF_create(<span class="number">2000</span>)</span><br><span class="line">        <span class="comment"># find keypoints and descriptors directly</span></span><br><span class="line">        kps, des = detector.detectAndCompute(gray, <span class="keyword">None</span>)</span><br><span class="line">        img = cv2.drawKeypoints(image=img, outImage=img, keypoints=kps, \ </span><br><span class="line">            flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">        feature_name = images_folder + <span class="string">'features%s%s.feature'</span>%(os.sep, filename)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            np.savetxt(feature_name, des, fmt=<span class="string">'%.5e'</span>) <span class="comment"># 保存特征向量</span></span><br><span class="line">            <span class="comment"># feature = np.loadtxt(feature_folder + filename) # 加载特征向量</span></span><br><span class="line">            <span class="comment"># cv2.imwrite(drawpath, img) # 保存绘制了SURF特征的图片</span></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        featureSum += len(kps)</span><br><span class="line">    <span class="keyword">print</span> featureSum</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    images_folder = path + <span class="string">'images'</span> + os.sep</span><br><span class="line">    draw_folder = path + <span class="string">'results'</span> + os.sep + <span class="string">'drawImages'</span> + os.sep</span><br><span class="line">    feature_extract(images_folder, draw_folder)</span><br></pre></td></tr></table></figure></p><p>以上，欢迎交流～</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一、算法背景介绍&quot;&gt;&lt;a href=&quot;#一、算法背景介绍&quot; class=&quot;headerlink&quot; title=&quot;一、算法背景介绍&quot;&gt;&lt;/a&gt;一、算法背景介绍&lt;/h2&gt;&lt;p&gt;Lowe于2000年提出了SIFT算法，并于2004年加以完善和改进，SIFT特征对图像旋转、平移、缩放、亮度变化能够保持良好的不变性，且其独特性好，信息量较为丰富，得到了广泛的应用，但其提取计算量较大，效率较低，因此Bay等人提出了SURF算法，在保证特征点数量的情况下，提高了效率。&lt;br&gt;SURF算法首先构建Hessian矩阵，然后构建尺度空间(SIFT算法则使用DOG)，其在构建图像金字塔时原始图像大小保持不变，只改变滤波器大小，然后精确定位特征点并确定其主方向，最后生成特征点描述子。&lt;br&gt;此外，SURF算法得到的特征向量维度为64，而SIFT得到的是128维向量。&lt;br&gt;
    
    </summary>
    
      <category term="图像处理" scheme="http://maself.top/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
      <category term="python" scheme="http://maself.top/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/python/"/>
    
    
      <category term="python" scheme="http://maself.top/tags/python/"/>
    
      <category term="surf特征" scheme="http://maself.top/tags/surf%E7%89%B9%E5%BE%81/"/>
    
      <category term="特征提取与保存" scheme="http://maself.top/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E4%B8%8E%E4%BF%9D%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>python下进行hsv颜色空间量化</title>
    <link href="http://maself.top/py-hsv-quantilize/"/>
    <id>http://maself.top/py-hsv-quantilize/</id>
    <published>2018-04-30T05:41:49.000Z</published>
    <updated>2018-05-03T02:22:47.692Z</updated>
    
    <content type="html"><![CDATA[<p>由于工作需要，需要计算颜色直方图来提取颜色特征，但若不将颜色空间进行量化，则直方图矢量维数过高，不便于使用。但是看了<strong>opencv API</strong>后并未发现提供了相关函数能够在计算颜色直方图的同时进行量化，因此这部分功能只能自己实现。下面分为两个部分进行介绍：<br><a id="more"></a></p><h2 id="一、颜色空间量化表"><a href="#一、颜色空间量化表" class="headerlink" title="一、颜色空间量化表"></a>一、颜色空间量化表</h2><p>由于RGB模型不够直观，不符合人类视觉习惯，因此在进行颜色特征提取前，需要将照片从RGB颜色模型转换为更符合人类视觉的HSV模型。在提取颜色特征时，最常用的方法之一为颜色直方图法，但一张图片中出现的颜色一般特别多，导致直方图矢量的维数较高，因此需要对HSV空间进行量化。根据人眼对颜色的感知特性，采用较为常用的量化方法，即按照如下对应关系进行量化：<br><img src="http://p81hctxgb.bkt.clouddn.com/hsv.png" alt="HSV量化对照表"><br>基于上述量化表，将各颜色分量按照下述公式合成为72维一维矢量： $G = 9H + 3S + V$</p><h2 id="二、量化代码"><a href="#二、量化代码" class="headerlink" title="二、量化代码"></a>二、量化代码</h2><p>代码使用纯python写成，效率偏低，处理388*500像素的照片用时1.45秒。在quantilize函数中，未使用if-else判断语句，因此至少节省了1/3的时间。但这个速度显然是无法令人满意的，用C++效率应该会更高点。如果有人有更好的想法，欢迎在下方评论交流。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*-coding:utf-8-*-</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">colors</span><span class="params">(imagepath)</span>:</span></span><br><span class="line">    img = cv2.imread(imagepath)</span><br><span class="line">    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)</span><br><span class="line">    nhsv = np.zeros(hsv.shape[:<span class="number">2</span>], dtype=np.uint8)</span><br><span class="line">    t2 = datetime.now()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(hsv.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(hsv.shape[<span class="number">1</span>]):</span><br><span class="line">            nhsv[i][j] = quantilize(hsv[i][j])</span><br><span class="line">    <span class="keyword">print</span> datetime.now() - t2</span><br><span class="line">    hist = cv2.calcHist([nhsv], [<span class="number">0</span>], <span class="keyword">None</span>, [<span class="number">72</span>], [<span class="number">0</span>,<span class="number">72</span>]) <span class="comment"># 40x faster than np.histogramfaster than np.histogram</span></span><br><span class="line">    plt.plot(hist,color = <span class="string">'r'</span>)</span><br><span class="line">    plt.xlim([<span class="number">0</span>, <span class="number">72</span>])</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quantilize</span><span class="params">(value)</span>:</span></span><br><span class="line">    <span class="string">'''hsv直方图量化</span></span><br><span class="line"><span class="string">    value : [21, 144, 23] h, s, v</span></span><br><span class="line"><span class="string">    opencv中，h-[0,180], s-[0,255], v-[0,255]</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    value[<span class="number">0</span>] = value[<span class="number">0</span>] * <span class="number">2</span></span><br><span class="line">    hlist = [<span class="number">20</span>, <span class="number">40</span>, <span class="number">75</span>, <span class="number">155</span>, <span class="number">190</span>, <span class="number">270</span>, <span class="number">290</span>, <span class="number">316</span>, <span class="number">360</span>]</span><br><span class="line">    svlist = [<span class="number">21</span>, <span class="number">178</span>, <span class="number">255</span>]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(hlist)):</span><br><span class="line">        <span class="keyword">if</span> value[<span class="number">0</span>] &lt;= hlist[i]:</span><br><span class="line">            h = i % <span class="number">8</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(svlist)):</span><br><span class="line">        <span class="keyword">if</span> value[<span class="number">1</span>] &lt;= svlist[i]:</span><br><span class="line">            s = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(svlist)):</span><br><span class="line">        <span class="keyword">if</span> value[<span class="number">2</span>] &lt;= svlist[i]:</span><br><span class="line">            v = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">9</span> * h + <span class="number">3</span> * s + v</span><br></pre></td></tr></table></figure></p><p>以上，欢迎批评交流～<br>如果觉得不错，欢迎点赞～</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;由于工作需要，需要计算颜色直方图来提取颜色特征，但若不将颜色空间进行量化，则直方图矢量维数过高，不便于使用。但是看了&lt;strong&gt;opencv API&lt;/strong&gt;后并未发现提供了相关函数能够在计算颜色直方图的同时进行量化，因此这部分功能只能自己实现。下面分为两个部分进行介绍：&lt;br&gt;
    
    </summary>
    
      <category term="图像处理" scheme="http://maself.top/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
      <category term="python" scheme="http://maself.top/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/python/"/>
    
    
      <category term="python" scheme="http://maself.top/tags/python/"/>
    
      <category term="hsv量化" scheme="http://maself.top/tags/hsv%E9%87%8F%E5%8C%96/"/>
    
      <category term="颜色空间" scheme="http://maself.top/tags/%E9%A2%9C%E8%89%B2%E7%A9%BA%E9%97%B4/"/>
    
  </entry>
  
</feed>
